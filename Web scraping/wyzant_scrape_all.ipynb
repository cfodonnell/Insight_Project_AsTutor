{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:76.0) Gecko/20100101 Firefox/76.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_add = 'https://www.wyzant.com/match/search?sort=1&d=20&utc_offset=-5&min_price=10&max_price=200&min_age=18&max_age=100&gender_pref=none&st=5&kw=physics&ol=false&z='\n",
    "zip_code = 78750\n",
    "url = search_add + str(zip_code)\n",
    "\n",
    "chromedriver = '/home/codonnell/chromedriver.exe'\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "driver.get(url)\n",
    "\n",
    "#run this, then physically enter fields to get to search page\n",
    "#then reopen search url above and it should work this time\n",
    "#search for all tutor links on page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tutor_info(zip_code, links, headers):\n",
    "    \n",
    "    mains = []\n",
    "    scheds = []\n",
    "    empty = {'sunday': [None], 'monday': [None], 'tuesday': [None], 'wednesday': [None],\n",
    "         'thursday': [None], 'friday': [None], 'saturday': [None]}\n",
    "    \n",
    "    for i, link in enumerate(links):\n",
    "        r = requests.get(link, headers = headers).text\n",
    "        soup = BeautifulSoup(r, 'html.parser')\n",
    "\n",
    "        tags = soup.find_all('script')\n",
    "        try:\n",
    "            time_tutoring = soup.find_all('h3')[0].text\n",
    "        except:\n",
    "            time_tutoring = []\n",
    "        bio_list = soup.find_all('p', {'class':  'spc-zero-n spc-sm-s'})\n",
    "        bio = [part.text for part in bio_list]\n",
    "        \n",
    "        if soup.find_all('i' ,{'class':'wc-background-pass wc-green'}):\n",
    "            bck = 1\n",
    "            bck_passed = soup.find_all('p', {'class':\"spc-zero\"})[1].text\n",
    "        else:\n",
    "            bck = 0\n",
    "            bck_passed = []\n",
    "            \n",
    "        edu = soup.find_all('section' ,{'class':\"spc-med-s\"})\n",
    "        if edu:\n",
    "            educ =[e.text for e in edu]\n",
    "        else:\n",
    "            educ = []\n",
    "        \n",
    "        main_details = json.loads(tags[0].string)\n",
    "        main_details['time_tutoring'] = time_tutoring\n",
    "        main_details['bio'] = bio\n",
    "        main_details['background_check'] = bck\n",
    "        main_details['date_background_passed'] = bck_passed\n",
    "        main_details['education'] = educ\n",
    "        \n",
    "        mains.append(main_details)\n",
    "        try:\n",
    "            scheds.append(json.loads(tags[6].string.split('=')[1][:-1]))\n",
    "        except:\n",
    "            scheds.append(empty)\n",
    "        time.sleep(np.random.rand()*5)\n",
    "        \n",
    "    df = pd.merge(pd.DataFrame(mains), pd.DataFrame(scheds), left_index=True, right_index=True)\n",
    "    df.to_csv('/home/codonnell/tutors/tutnew/tutors_' + str(zip_code) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tut_id(unique_tuts):\n",
    "    with open('/home/codonnell/tutors_ids.txt', 'w') as filehandle:\n",
    "        for item in unique_tuts:\n",
    "            filehandle.write('%s\\n' % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([60004, 60016, 60056, 60073, 60085, 60120, 60148, 60402, 60411,\n",
       "       60440, 60453, 60505, 60506, 60608, 60609, 60614, 60617, 60618,\n",
       "       60619, 60620, 60623, 60625, 60628, 60630, 60632, 60634, 60638,\n",
       "       60639, 60640, 60641, 60643, 60647, 60651, 60657, 60804])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "already_done = [77449,11368,60629,90011,79936,30044,80209,89138,28208,84102,98122,33128,\n",
    "               46201, 55401,43215,19102,94108,22046,91911,37128,85001,78214,48201,63108,\n",
    "               80303, 926, 8701]\n",
    "pop_zips = pd.read_csv('/home/codonnell/Insight/Insight_Project_AsTutor/data/raw/zips_incomes/zips_il.csv')\n",
    "\n",
    "np.setdiff1d(pop_zips['zip_code'].values,already_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "zips = np.setdiff1d(pop_zips['zip_code'].values,already_done)[-7:]\n",
    "#zips = already_done\n",
    "subjects = ['physics', 'math', 'spanish', 'english', 'computer']\n",
    "links = []\n",
    "tot_tuts = []\n",
    "\n",
    "for zip_code in zips:\n",
    "    links = []\n",
    "    tot_tuts = []\n",
    "    \n",
    "    for subject in subjects:\n",
    "            \n",
    "        url = 'https://www.wyzant.com/match/search?sort=1&d=20&utc_offset=-5&min_price=10&max_price=200&min_age=18&max_age=100&gender_pref=none&st=0&kw=' + subject + '&ol=false&z=' + str(zip_code)\n",
    "        driver.get(url)\n",
    "        \n",
    "        try:\n",
    "            num_tuts = driver.find_elements_by_tag_name('strong')[2].text #per subject given zip\n",
    "        except:\n",
    "            num_tuts = 0\n",
    "        \n",
    "        lks = driver.find_elements_by_xpath('.//a[@class=\"tutor-card flex\"]')\n",
    "        lks_found = [link.get_attribute('href') for link in lks]\n",
    "        links.append(lks_found)\n",
    "        \n",
    "        try:\n",
    "            if int(num_tuts.split(' ')[0]) > 10:\n",
    "                extras = int(np.floor(int(num_tuts.split(' ')[0])/10)) + 1\n",
    "                for i in range(1,extras):\n",
    "                    urlmore = 'https://www.wyzant.com/match/search/more?d=20&gender_pref=none&kw=' + subject + '&max_age=100&max_price=500&min_age=18&min_price=10&ol=false&page_number=' + str(i) + '&sort=1&st=0&utc_offset=-5&z=' +str(zip_code)\n",
    "                    driver.get(urlmore)\n",
    "                    more_lks = driver.find_elements_by_xpath('.//a[@class=\"tutor-card flex\"]')\n",
    "                    more_lks_found = [link.get_attribute('href') for link in more_lks]\n",
    "                    links.append(more_lks_found)\n",
    "                    time.sleep(np.random.rand()*5)\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "            \n",
    "        tot_tuts.append(num_tuts) #per subject given zip\n",
    "            \n",
    "            \n",
    "        time.sleep(np.random.rand()*5)\n",
    "    \n",
    "    unique_tuts = np.unique(np.array([item for sublist in links for item in sublist]))\n",
    "    save_tut_id(unique_tuts)\n",
    "    get_tutor_info(zip_code, unique_tuts, headers)\n",
    "    tut_num_df = pd.DataFrame({'zip_code': [str(zip_code)]*5, 'tot_tuts': tot_tuts})\n",
    "    tut_num_df.to_csv('/home/codonnell/tutors//tutnew/tut_num_' +str(zip_code) + '.csv')\n",
    "    \n",
    "    time.sleep(np.random.rand()*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver.get(url)\n",
    "num_tuts = driver.find_elements_by_tag_name('strong')[2].text #per subject given zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(1,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
