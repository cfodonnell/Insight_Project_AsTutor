{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import pickle\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:76.0) Gecko/20100101 Firefox/76.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_add = 'https://www.wyzant.com/match/search?sort=1&d=20&utc_offset=-5&min_price=10&max_price=200&min_age=18&max_age=100&gender_pref=none&st=5&kw=physics&ol=false&z='\n",
    "zip_code = 78750\n",
    "url = search_add + str(zip_code)\n",
    "\n",
    "chromedriver = '/home/codonnell/chromedriver.exe'\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "driver.get(url)\n",
    "\n",
    "#run this, then physically enter fields to get to search page\n",
    "#then reopen search url above and it should work this time\n",
    "#search for all tutor links on page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tutor_info(zip_code, links, headers):\n",
    "    \n",
    "    mains = []\n",
    "    scheds = []\n",
    "\n",
    "    empty = {'sunday': [None], 'monday': [None], 'tuesday': [None], 'wednesday': [None],\n",
    "         'thursday': [None], 'friday': [None], 'saturday': [None]}\n",
    "    \n",
    "    for i, link in enumerate(links):\n",
    "        r = requests.get(link, headers = headers).text\n",
    "        soup = BeautifulSoup(r, 'html.parser')\n",
    "\n",
    "        tags = soup.find_all('script')\n",
    "        try:\n",
    "            time_tutoring = soup.find_all('h3')[0].text\n",
    "        except:\n",
    "            time_tutoring = []\n",
    "        bio_list = soup.find_all('p', {'class':  'spc-zero-n spc-sm-s'})\n",
    "        bio = [part.text for part in bio_list]\n",
    "        \n",
    "        if soup.find_all('i' ,{'class':'wc-background-pass wc-green'}):\n",
    "            bck = 1\n",
    "            bck_passed = soup.find_all('p', {'class':\"spc-zero\"})[1].text\n",
    "        else:\n",
    "            bck = 0\n",
    "            bck_passed = []\n",
    "            \n",
    "        edu = soup.find_all('section' ,{'class':\"spc-med-s\"})\n",
    "        if edu:\n",
    "            educ =[e.text for e in edu]\n",
    "        else:\n",
    "            educ = []\n",
    "        \n",
    "        try:\n",
    "            main_details = json.loads(tags[0].string)\n",
    "            main_details['time_tutoring'] = time_tutoring\n",
    "            main_details['bio'] = bio\n",
    "            main_details['background_check'] = bck\n",
    "            main_details['date_background_passed'] = bck_passed\n",
    "            main_details['education'] = educ\n",
    "        \n",
    "            mains.append(main_details)\n",
    "            try:\n",
    "                scheds.append(json.loads(tags[6].string.split('=')[1][:-1]))\n",
    "            except:\n",
    "                scheds.append(empty)\n",
    "        except:\n",
    "            pass\n",
    "                \n",
    "        time.sleep(np.random.rand()*5)\n",
    "        \n",
    "    df = pd.merge(pd.DataFrame(mains), pd.DataFrame(scheds), left_index=True, right_index=True)\n",
    "    df.to_csv('/home/codonnell/tutors/tutnew/tutors_' + str(zip_code) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tut_id(unique_tuts):\n",
    "    with open('/home/codonnell/tutors_ids.txt', 'w') as filehandle:\n",
    "        for item in unique_tuts:\n",
    "            filehandle.write('%s\\n' % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30004, 30016, 30022, 30024, 30032, 30034, 30039, 30040, 30041,\n",
       "       30043, 30047, 30052, 30058, 30062, 30064, 30066, 30067, 30075,\n",
       "       30076, 30080, 30083, 30093, 30096, 30097, 30101, 30114, 30127,\n",
       "       30134, 30135, 30144, 30157, 30188, 30236, 30253, 30263, 30281,\n",
       "       30318, 30331, 30349, 30506, 30518, 30606, 30721, 30906, 30907,\n",
       "       30909, 31088, 31419, 31907, 80003, 80004, 80010, 80011, 80012,\n",
       "       80013, 80014, 80015, 80016, 80017, 80020, 80021, 80022, 80027,\n",
       "       80031, 80111, 80122, 80123, 80126, 80127, 80128, 80134, 80138,\n",
       "       80204, 80205, 80210, 80211, 80219, 80220, 80221, 80226, 80227,\n",
       "       80228, 80229, 80231, 80233, 80239, 80241, 80260, 80401, 80501,\n",
       "       80503, 80504, 80524, 80525, 80526, 80537, 80538, 80601, 80631,\n",
       "       80634, 80906, 80909, 80911, 80916, 80917, 80918, 80920, 81001,\n",
       "       81005, 81007, 81504, 98003, 98004, 98006, 98012, 98023, 98026,\n",
       "       98030, 98031, 98032, 98033, 98034, 98036, 98042, 98052, 98056,\n",
       "       98058, 98059, 98092, 98103, 98105, 98115, 98118, 98125, 98133,\n",
       "       98155, 98168, 98198, 98203, 98204, 98208, 98223, 98225, 98226,\n",
       "       98258, 98270, 98277, 98366, 98374, 98387, 98391, 98444, 98501,\n",
       "       98503, 98513, 98584, 98604, 98632, 98661, 98682, 98801, 98837,\n",
       "       98902, 98908, 99205, 99206, 99208, 99301, 99336, 99362])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "already_done = [77449,11368,60629,90011,79936,30044,80209,89138,28208,84102,98122,33128,\n",
    "               46201, 55401,43215,19102,94108,22046,91911,37128,85001,78214,48201,63108,\n",
    "               80303, 926, 8701]\n",
    "pop_zips = pd.read_csv('/home/codonnell/Insight/Insight_Project_AsTutor/data/raw/zips_incomes/zips_ga_co_wa.csv')\n",
    "\n",
    "np.setdiff1d(pop_zips['zip_code'].values,already_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "zips = np.setdiff1d(pop_zips['zip_code'].values,already_done)[-7:]\n",
    "#zips = already_done\n",
    "subjects = ['physics', 'math', 'spanish', 'english', 'computer']\n",
    "links = []\n",
    "tot_tuts = []\n",
    "\n",
    "for zip_code in zips:\n",
    "    links = []\n",
    "    tot_tuts = []\n",
    "    \n",
    "    for subject in subjects:\n",
    "            \n",
    "        url = 'https://www.wyzant.com/match/search?sort=1&d=20&utc_offset=-5&min_price=10&max_price=200&min_age=18&max_age=100&gender_pref=none&st=0&kw=' + subject + '&ol=false&z=' + str(zip_code)\n",
    "        driver.get(url)\n",
    "        \n",
    "        try:\n",
    "            num_tuts = driver.find_elements_by_tag_name('strong')[2].text #per subject given zip\n",
    "        except:\n",
    "            num_tuts = 0\n",
    "        \n",
    "        lks = driver.find_elements_by_xpath('.//a[@class=\"tutor-card flex\"]')\n",
    "        lks_found = [link.get_attribute('href') for link in lks]\n",
    "        links.append(lks_found)\n",
    "        \n",
    "        try:\n",
    "            if int(num_tuts.split(' ')[0]) > 10:\n",
    "                extras = int(np.floor(int(num_tuts.split(' ')[0])/10)) + 1\n",
    "                for i in range(1,extras):\n",
    "                    urlmore = 'https://www.wyzant.com/match/search/more?d=20&gender_pref=none&kw=' + subject + '&max_age=100&max_price=500&min_age=18&min_price=10&ol=false&page_number=' + str(i) + '&sort=1&st=0&utc_offset=-5&z=' +str(zip_code)\n",
    "                    driver.get(urlmore)\n",
    "                    more_lks = driver.find_elements_by_xpath('.//a[@class=\"tutor-card flex\"]')\n",
    "                    more_lks_found = [link.get_attribute('href') for link in more_lks]\n",
    "                    links.append(more_lks_found)\n",
    "                    time.sleep(np.random.rand()*5)\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "            \n",
    "        tot_tuts.append(num_tuts) #per subject given zip\n",
    "            \n",
    "            \n",
    "        time.sleep(np.random.rand()*5)\n",
    "    \n",
    "    unique_tuts = np.unique(np.array([item for sublist in links for item in sublist]))\n",
    "    save_tut_id(unique_tuts)\n",
    "    get_tutor_info(zip_code, unique_tuts, headers)\n",
    "    tut_num_df = pd.DataFrame({'zip_code': [str(zip_code)]*5, 'tot_tuts': tot_tuts})\n",
    "    tut_num_df.to_csv('/home/codonnell/tutors//tutnew/tut_num_' +str(zip_code) + '.csv')\n",
    "    \n",
    "    time.sleep(np.random.rand()*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_done = [77449,11368,60629,90011,79936,30044,80209,89138,28208,84102,98122,33128,\n",
    "               46201, 55401,43215,19102,94108,22046,91911,37128,85001,78214,48201,63108,\n",
    "               80303, 926, 8701]\n",
    "#state = 'nv_nj_nm'\n",
    "state = 'ol'\n",
    "#pop_zips = pd.read_csv('/home/codonnell/Insight/Insight_Project_AsTutor/data/raw/zips_incomes/zips_' + state + '.csv')\n",
    "\n",
    "#np.setdiff1d(pop_zips['zip_code'].values,already_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zips = np.setdiff1d(pop_zips['zip_code'].values,already_done)\n",
    "#zips = already_done\n",
    "zips = [78751]\n",
    "subjects = ['physics', 'math', 'spanish', 'english', 'computer']\n",
    "links = []\n",
    "tot_tuts_dfs = []\n",
    "\n",
    "for zip_code in zips:\n",
    "    tot_tuts = []\n",
    "    \n",
    "    for subject in subjects:\n",
    "            \n",
    "        url = 'https://www.wyzant.com/match/search?sort=1&d=20&utc_offset=-5&min_price=10&max_price=200&min_age=18&max_age=100&gender_pref=none&st=0&kw=' + subject + '&ol=true&z=' + str(zip_code)\n",
    "        driver.get(url)\n",
    "        \n",
    "        try:\n",
    "            num_tuts = driver.find_elements_by_tag_name('strong')[2].text #per subject given zip\n",
    "        except:\n",
    "            num_tuts = 0\n",
    "        \n",
    "        lks = driver.find_elements_by_xpath('.//a[@class=\"tutor-card flex\"]')\n",
    "        lks_found = [link.get_attribute('href') for link in lks]\n",
    "        links.append(lks_found)\n",
    "        \n",
    "        try:\n",
    "            if int(num_tuts.split(' ')[0].replace(',','')) > 10:\n",
    "                extras = int(np.floor(int(num_tuts.split(' ')[0].replace(',',''))/10)) + 1\n",
    "                for i in range(1,extras):\n",
    "                    urlmore = 'https://www.wyzant.com/match/search/more?d=20&gender_pref=none&kw=' + subject + '&max_age=100&max_price=500&min_age=18&min_price=10&ol=true&page_number=' + str(i) + '&sort=1&st=0&utc_offset=-5&z=' +str(zip_code)\n",
    "                    driver.get(urlmore)\n",
    "                    more_lks = driver.find_elements_by_xpath('.//a[@class=\"tutor-card flex\"]')\n",
    "                    more_lks_found = [link.get_attribute('href') for link in more_lks]\n",
    "                    links.append(more_lks_found)\n",
    "                    time.sleep(np.random.rand()*5)\n",
    "            else:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "            \n",
    "        tot_tuts.append(num_tuts) #per subject given zip\n",
    "        time.sleep(np.random.rand()*5)\n",
    "        \n",
    "    tot_tuts_dfs.append(pd.DataFrame({'zip_code': [str(zip_code)]*5, 'tot_tuts': tot_tuts}))\n",
    "    time.sleep(np.random.rand()*5)      \n",
    "            \n",
    "    \n",
    "unique_tuts = np.unique(np.array([item for sublist in links for item in sublist]))\n",
    "save_tut_id(unique_tuts)\n",
    "get_tutor_info(state, unique_tuts, headers)\n",
    "tut_num_df = pd.concat(tot_tuts_dfs)\n",
    "tut_num_df.to_csv('/home/codonnell/tutors//tutnew/tut_num_' + state + '.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '3,159'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-b6d5df701abb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_tuts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '3,159'"
     ]
    }
   ],
   "source": [
    "int(np.floor(int(num_tuts.split(' ')[0])/10)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'400'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tutor_info(state, unique_tuts, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'https://www.wyzant.com/match/search?sort=1&d=20&utc_offset=-5&min_price=10&max_price=200&min_age=18&max_age=100&gender_pref=none&st=5&kw=physics&ol=false&z='\n",
    "'https://www.wyzant.com/match/search?sort=1&d=20&utc_offset=-5&min_price=10&max_price=200&min_age=18&max_age=100&gender_pref=none&st=0&kw=' + subject + '&ol=false&z=' + str(zip_code)\n",
    "'https://www.wyzant.com/match/search?sort=1&d=20&utc_offset=-5&min_price=10&max_price=200&min_age=18&max_age=100&gender_pref=none&st=0&kw=' + subject + '&ol=false&z=' + str(zip_code)\n",
    "'https://www.wyzant.com/match/search?sort=1&d=20&utc_offset=-5&min_price=10&max_price=200&min_age=18&max_age=100&gender_pref=none&st=0&kw=' + subject + '&ol=false&z=' + str(zip_code)\n",
    "https://www.wyzant.com/match/search?sort=1&d=20&utc_offset=-5&min_price=10&max_price=200&min_age=18&max_age=100&gender_pref=none&st=0&kw=english&ol=false&z=78751"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
